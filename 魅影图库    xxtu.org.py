import requests
from bs4 import BeautifulSoup
import concurrent.futures
from PIL import Image
import io
import os
import time
import random
import argparse
import logging
import shutil
import re
import sys
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# è®¾ç½®æ—¥å¿—æ ¼å¼
log_file = "crawler.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ç¦ç”¨æ‰€æœ‰ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—
for name in logging.root.manager.loggerDict:
    if name not in ['__main__', 'crawler']:
        logging.getLogger(name).setLevel(logging.CRITICAL)

class GalleryCrawler:
    def __init__(self, save_path, verify=False):
        self.save_path = save_path
        self.verify = verify
        self.session = self._create_session()
        
        # åˆå§‹åŒ–åˆ—è¡¨
        self.waiting_list = []
        self.downloading_list = []
        self.completed_list = []
        self.failed_list = []
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        if not os.path.exists(self.save_path):
            os.makedirs(self.save_path)
    
    def _create_session(self):
        """åˆ›å»ºå¸¦è¿æ¥æ± å’Œé‡è¯•æœºåˆ¶çš„session"""
        session = requests.Session()
        retry = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        adapter = HTTPAdapter(max_retries=retry, pool_connections=100, pool_maxsize=100)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        # è®¾ç½®headersæ¨¡æ‹Ÿæµè§ˆå™¨
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        return session
    
    def _sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œå°†ç‰¹æ®Šå­—ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼"""
        return re.sub(r'[\\/:*?"<>|]', ' ', filename)
    
    def get_all_albums(self):
        """è·å–æ‰€æœ‰ç›¸å†Œé“¾æ¥å’Œåç§°"""
        base_url = "https://xxtu.org/"
        albums = []
        page = 1
        max_pages = 100  # è®¾ç½®è¾ƒå¤§çš„æœ€å¤§é¡µæ•°é™åˆ¶ï¼Œç¡®ä¿è·å–æ‰€æœ‰ç›¸å†Œ
        
        logger.info("å¼€å§‹è·å–æ‰€æœ‰ç›¸å†Œ...")
        print("ğŸš€ å¼€å§‹è·å–æ‰€æœ‰ç›¸å†Œ...")
        
        while page <= max_pages:
            try:
                # æ„å»ºåˆ†é¡µURL
                if page == 1:
                    current_url = base_url
                else:
                    current_url = f"{base_url}?paged={page}"
                
                logger.info(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µç›¸å†Œï¼ŒURL: {current_url}")
                print(f"ğŸ“„ æ­£åœ¨è·å–ç¬¬ {page} é¡µç›¸å†Œï¼ŒURL: {current_url}")
                # éšæœºå»¶è¿Ÿ4-8ç§’
                delay = random.uniform(4, 8)
                print(f"â±ï¸  éšæœºå»¶è¿Ÿ {delay:.1f} ç§’...")
                time.sleep(delay)
                
                # è·å–é¡µé¢å†…å®¹
                start_time = time.time()
                response = self.session.get(current_url, timeout=30)
                response.raise_for_status()
                end_time = time.time()
                
                # è®¡ç®—ä¸‹è½½é€Ÿåº¦
                content_length = len(response.content)
                elapsed_time = end_time - start_time
                if elapsed_time > 0:
                    speed = content_length / elapsed_time / 1024  # KB/s
                    print(f"ğŸ“¥ é¡µé¢ä¸‹è½½å®Œæˆï¼Œå¤§å°: {content_length/1024:.1f} KBï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’ï¼Œé€Ÿåº¦: {speed:.1f} KB/s")
                
                # è§£æé¡µé¢
                print(f"ğŸ” æ­£åœ¨è§£æé¡µé¢...")
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # æŸ¥æ‰¾æ‰€æœ‰ç›¸å†Œé¡¹ - ä¼˜åŒ–é€‰æ‹©å™¨ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°æ‰€æœ‰ç›¸å†Œé¡¹
                album_items = soup.find_all('article')
                if not album_items:
                    # å°è¯•å¦ä¸€ç§å¯èƒ½çš„é€‰æ‹©å™¨
                    print(f"ğŸ” æœªæ‰¾åˆ°articleæ ‡ç­¾ï¼Œå°è¯•ä½¿ç”¨div.posté€‰æ‹©å™¨...")
                    album_items = soup.find_all('div', class_='post')
                
                if not album_items:
                    logger.info(f"ç¬¬ {page} é¡µæœªæ‰¾åˆ°ç›¸å†Œé¡¹ï¼Œå·²è·å–å…¨éƒ¨ç›¸å†Œ")
                    print(f"ğŸ“„ ç¬¬ {page} é¡µæœªæ‰¾åˆ°ç›¸å†Œé¡¹ï¼Œå·²è·å–å…¨éƒ¨ç›¸å†Œ")
                    break
                
                print(f"âœ… æ‰¾åˆ° {len(album_items)} ä¸ªç›¸å†Œé¡¹")
                
                # æå–ç›¸å†Œä¿¡æ¯
                new_albums = 0
                print(f"ğŸ“¸ æ­£åœ¨æå–ç›¸å†Œä¿¡æ¯...")
                for item in album_items:
                    # æŸ¥æ‰¾ç›¸å†Œé“¾æ¥
                    a_tag = item.find('a')
                    if a_tag and 'href' in a_tag.attrs:
                        album_url = a_tag['href']
                        # æŸ¥æ‰¾ç›¸å†Œåç§°
                        title_tag = item.find('h2', class_='entry-title')
                        if not title_tag:
                            # å°è¯•å…¶ä»–å¯èƒ½çš„æ ‡é¢˜æ ‡ç­¾
                            title_tag = item.find('h1', class_='entry-title')
                            if not title_tag:
                                title_tag = item.find('h3', class_='entry-title')
                        
                        if title_tag:
                            album_name = title_tag.text.strip()
                            # æ¸…ç†ç›¸å†Œåç§°ï¼Œç”¨äºæ–‡ä»¶å¤¹å‘½å
                            sanitized_name = self._sanitize_filename(album_name)
                            
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥ç›¸å†Œ
                            album_exists = any(existing_album[2] == album_url for existing_album in albums)
                            if not album_exists:
                                albums.append((sanitized_name, album_name, album_url))
                                new_albums += 1
                                print(f"ğŸ‰ æ£€ç´¢åˆ°ç›¸å†Œ: {album_name}")
                
                logger.info(f"ç¬¬ {page} é¡µæ–°å¢ {new_albums} ä¸ªç›¸å†Œï¼Œç´¯è®¡ {len(albums)} ä¸ªç›¸å†Œ")
                print(f"ğŸ“Š ç¬¬ {page} é¡µå¤„ç†å®Œæˆï¼Œæ–°å¢ {new_albums} ä¸ªç›¸å†Œï¼Œç´¯è®¡ {len(albums)} ä¸ªç›¸å†Œ")
                
                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æ–°ç›¸å†Œ
                if new_albums == 0:
                    logger.info(f"ç¬¬ {page} é¡µæœªæ–°å¢ä»»ä½•ç›¸å†Œï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæœ€åä¸€é¡µ")
                    print(f"ğŸ“„ ç¬¬ {page} é¡µæœªæ–°å¢ä»»ä½•ç›¸å†Œï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæœ€åä¸€é¡µ")
                    # å¦‚æœè¿ç»­2é¡µæ²¡æœ‰æ–°å¢ç›¸å†Œï¼Œæˆ–è€…é¡µç è¶…è¿‡5é¡µï¼Œåˆ™åœæ­¢
                    if page > 5:  # ç¡®ä¿è‡³å°‘è·å–5é¡µ
                        print(f"ğŸ‰ å·²è·å–åˆ° {len(albums)} ä¸ªç›¸å†Œï¼Œç»“æŸç›¸å†Œè·å–")
                        break
                
                # ç»§ç»­è·å–ä¸‹ä¸€é¡µ
                page += 1
                    
            except requests.exceptions.HTTPError as e:
                # å¤„ç†HTTPé”™è¯¯
                if e.response.status_code == 404:
                    # 404é”™è¯¯ï¼Œè¯´æ˜é¡µé¢ä¸å­˜åœ¨ï¼Œæ˜¯æœ€åä¸€é¡µ
                    logger.info(f"ç¬¬ {page} é¡µè¿”å›404é”™è¯¯ï¼Œå·²åˆ°è¾¾æœ€åä¸€é¡µ")
                    print(f"âœ… ç¬¬ {page} é¡µè¿”å›404é”™è¯¯ï¼Œå·²åˆ°è¾¾æœ€åä¸€é¡µ")
                    break
                else:
                    # å…¶ä»–HTTPé”™è¯¯ï¼Œé‡è¯•
                    logger.error(f"HTTPè¯·æ±‚å¤±è´¥: {e}")
                    print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {e}")
                    logger.info("æŒ‰ä»»æ„é”®é‡è¯•ï¼Œæˆ–æŒ‰Ctrl+Cé€€å‡º...")
                    input()
                    continue
            except requests.exceptions.RequestException as e:
                # å…¶ä»–ç½‘ç»œè¯·æ±‚é”™è¯¯ï¼Œé‡è¯•
                logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                logger.info("æŒ‰ä»»æ„é”®é‡è¯•ï¼Œæˆ–æŒ‰Ctrl+Cé€€å‡º...")
                input()
                continue
            except Exception as e:
                logger.error(f"è·å–ç¬¬ {page} é¡µç›¸å†Œå¤±è´¥: {e}")
                print(f"âŒ è·å–ç¬¬ {page} é¡µç›¸å†Œå¤±è´¥: {e}")
                # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆï¼Œä¾¿äºè°ƒè¯•
                import traceback
                traceback.print_exc()
                break
        
        logger.info(f"å…±æ‰¾åˆ° {len(albums)} ä¸ªç›¸å†Œ")
        print(f"ğŸ‰ ç›¸å†Œæ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(albums)} ä¸ªç›¸å†Œ")
        return albums
    
    def validate_image(self, image_path):
        """éªŒè¯å›¾ç‰‡æ˜¯å¦æŸå"""
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.getsize(image_path) == 0:
            logger.error(f"å›¾ç‰‡ {image_path} å¤§å°ä¸º0")
            return False
        
        # éªŒè¯å›¾ç‰‡å®Œæ•´æ€§
        try:
            with Image.open(image_path) as img:
                img.verify()
            return True
        except Exception as e:
            logger.error(f"å›¾ç‰‡ {image_path} æŸå: {e}")
            return False
    
    def download_image(self, image_url, save_path):
        """ä¸‹è½½å•å¼ å›¾ç‰‡"""
        retry_count = 0
        max_retries = 5
        
        img_name = os.path.basename(save_path)
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½å›¾ç‰‡: {img_name}")
        
        while retry_count < max_retries:
            try:
                # éšæœºå»¶è¿Ÿ4-8ç§’
                delay = random.uniform(4, 8)
                print(f"â±ï¸  éšæœºå»¶è¿Ÿ {delay:.1f} ç§’...")
                time.sleep(delay)
                
                # å‘é€è¯·æ±‚
                print(f"ğŸ”— æ­£åœ¨è¿æ¥: {image_url}")
                response = self.session.get(image_url, timeout=60, stream=True)
                response.raise_for_status()
                
                # éªŒè¯å“åº”çŠ¶æ€ç 
                if response.status_code != 200:
                    error_msg = f"âŒ å›¾ç‰‡é“¾æ¥è¿”å›çŠ¶æ€ç : {response.status_code}"
                    logger.error(f"å›¾ç‰‡é“¾æ¥ {image_url} è¿”å›çŠ¶æ€ç : {response.status_code}")
                    print(error_msg)
                    retry_count += 1
                    continue
                
                # éªŒè¯å“åº”å†…å®¹æ˜¯å¦ä¸ºå›¾ç‰‡
                content_type = response.headers.get('Content-Type', '')
                
                if not content_type.startswith('image/'):
                    error_msg = f"âŒ è¿”å›éå›¾ç‰‡å†…å®¹: {content_type}"
                    logger.error(f"å›¾ç‰‡é“¾æ¥ {image_url} è¿”å›éå›¾ç‰‡å†…å®¹: {content_type}")
                    print(error_msg)
                    retry_count += 1
                    continue
                
                # å†æ¬¡æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…å¹¶å‘ä¸‹è½½åŒä¸€æ–‡ä»¶ï¼‰
                if os.path.exists(save_path):
                    if self.validate_image(save_path):
                        info_msg = f"âœ… å›¾ç‰‡å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½"
                        logger.info(f"å›¾ç‰‡ {image_url} å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½")
                        print(info_msg)
                        return True
                    else:
                        info_msg = f"ğŸ”„ å›¾ç‰‡å·²å­˜åœ¨ä½†æŸåï¼Œé‡æ–°ä¸‹è½½"
                        logger.info(f"å›¾ç‰‡ {image_url} å·²å­˜åœ¨ä½†æŸåï¼Œé‡æ–°ä¸‹è½½")
                        print(info_msg)
                
                # è·å–æ–‡ä»¶å¤§å°
                content_length = response.headers.get('Content-Length')
                total_size = int(content_length) if content_length else 0
                if total_size > 0:
                    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size/1024:.1f} KB")
                
                # åŸå­åŒ–å†™å…¥æ–‡ä»¶
                temp_path = save_path + '.tmp'
                
                # ä¸‹è½½å¹¶ä¿å­˜æ–‡ä»¶
                print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°: {save_path}")
                start_time = time.time()
                downloaded_size = 0
                with open(temp_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            
                            # è®¡ç®—å¹¶æ˜¾ç¤ºä¸‹è½½è¿›åº¦å’Œé€Ÿåº¦
                            elapsed_time = time.time() - start_time
                            if elapsed_time > 0.5:  # æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡è¿›åº¦
                                speed = downloaded_size / elapsed_time / 1024  # KB/s
                                if total_size > 0:
                                    progress = downloaded_size / total_size * 100
                                    print(f"ğŸ“Š ä¸‹è½½è¿›åº¦: {progress:.1f}% ({downloaded_size/1024:.1f} KB/{total_size/1024:.1f} KB)ï¼Œé€Ÿåº¦: {speed:.1f} KB/s", end='\r')
                                else:
                                    print(f"ğŸ“Š ä¸‹è½½è¿›åº¦: {downloaded_size/1024:.1f} KBï¼Œé€Ÿåº¦: {speed:.1f} KB/s", end='\r')
                
                # ä¸‹è½½å®Œæˆï¼Œè®¡ç®—æ€»é€Ÿåº¦
                end_time = time.time()
                elapsed_time = end_time - start_time
                total_downloaded = downloaded_size
                if elapsed_time > 0:
                    speed = total_downloaded / elapsed_time / 1024  # KB/s
                    info_msg = f"ğŸ“Š ä¸‹è½½å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’ï¼Œé€Ÿåº¦: {speed:.1f} KB/s"
                    print(f"\n{info_msg}")
                    logger.info(f"[{img_name}] ä¸‹è½½å®Œæˆï¼Œæ–‡ä»¶å¤§å°: {total_downloaded} å­—èŠ‚ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’ï¼Œé€Ÿåº¦: {speed:.1f} KB/s")
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ä¸º0
                if total_downloaded == 0:
                    error_msg = f"âŒ ä¸‹è½½åæ–‡ä»¶å¤§å°ä¸º0"
                    logger.error(f"å›¾ç‰‡ {image_url} ä¸‹è½½åæ–‡ä»¶å¤§å°ä¸º0")
                    print(f"\n{error_msg}")
                    os.remove(temp_path)
                    retry_count += 1
                    continue
                
                # ç®€å•éªŒè¯æ–‡ä»¶å¼€å¤´çš„é­”æ³•æ•°å­—
                print(f"ğŸ” æ­£åœ¨éªŒè¯å›¾ç‰‡å®Œæ•´æ€§...")
                with open(temp_path, 'rb') as f:
                    magic_number = f.read(8)
                
                # å¸¸è§å›¾ç‰‡æ ¼å¼çš„é­”æ³•æ•°å­—
                valid_magic_numbers = {
                    b'\xFF\xD8\xFF': ['jpg', 'jpeg'],
                    b'\x89\x50\x4E\x47': ['png'],
                    b'\x47\x49\x46\x38': ['gif'],
                    b'\x42\x4D': ['bmp']
                }
                
                is_valid = False
                for magic, formats in valid_magic_numbers.items():
                    if magic_number.startswith(magic):
                        is_valid = True
                        break
                
                if not is_valid:
                    error_msg = f"âŒ å›¾ç‰‡é­”æ³•æ•°å­—æ— æ•ˆ: {magic_number}"
                    logger.error(f"å›¾ç‰‡ {image_url} é­”æ³•æ•°å­—æ— æ•ˆ: {magic_number}")
                    print(error_msg)
                    os.remove(temp_path)
                    retry_count += 1
                    continue
                
                # éªŒè¯å›¾ç‰‡å®Œæ•´æ€§
                if self.validate_image(temp_path):
                    try:
                        os.rename(temp_path, save_path)
                        success_msg = f"âœ… å›¾ç‰‡ä¸‹è½½å®Œæˆ: {img_name}"
                        print(success_msg)
                        return True
                    except FileExistsError:
                        # å¦‚æœæ–‡ä»¶åœ¨ä¸‹è½½è¿‡ç¨‹ä¸­è¢«å…¶ä»–çº¿ç¨‹åˆ›å»ºï¼Œå†æ¬¡éªŒè¯
                        os.remove(temp_path)
                        if os.path.exists(save_path):
                            if self.validate_image(save_path):
                                info_msg = f"âœ… å›¾ç‰‡å·²è¢«å…¶ä»–çº¿ç¨‹ä¸‹è½½å®Œæˆï¼Œè·³è¿‡"
                                logger.info(f"å›¾ç‰‡ {image_url} å·²è¢«å…¶ä»–çº¿ç¨‹ä¸‹è½½å®Œæˆï¼Œè·³è¿‡")
                                print(info_msg)
                                return True
                            else:
                                error_msg = f"âŒ å›¾ç‰‡å·²å­˜åœ¨ä½†æŸåï¼Œéœ€è¦é‡æ–°ä¸‹è½½"
                                logger.error(f"å›¾ç‰‡ {image_url} å·²å­˜åœ¨ä½†æŸåï¼Œéœ€è¦é‡æ–°ä¸‹è½½")
                                print(error_msg)
                                retry_count += 1
                                continue
                else:
                    error_msg = f"âŒ å›¾ç‰‡ä¸‹è½½åæŸåï¼Œæ­£åœ¨é‡è¯•... ({retry_count+1}/{max_retries})"
                    logger.error(f"å›¾ç‰‡ {image_url} ä¸‹è½½åæŸåï¼Œæ­£åœ¨é‡è¯•... ({retry_count+1}/{max_retries})")
                    print(error_msg)
                    os.remove(temp_path)
                    retry_count += 1
            except requests.exceptions.RequestException as e:
                retry_count += 1
                error_msg = f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}ï¼Œæ­£åœ¨é‡è¯•... ({retry_count}/{max_retries})"
                logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {e}ï¼Œæ­£åœ¨é‡è¯•... ({retry_count}/{max_retries})")
                print(error_msg)
                time.sleep(random.uniform(4, 8))
            except Exception as e:
                retry_count += 1
                error_msg = f"âŒ ä¸‹è½½å¤±è´¥: {e}ï¼Œæ­£åœ¨é‡è¯•... ({retry_count}/{max_retries})"
                logger.error(f"ä¸‹è½½å›¾ç‰‡ {image_url} å¤±è´¥: {e}ï¼Œæ­£åœ¨é‡è¯•... ({retry_count}/{max_retries})")
                print(error_msg)
                # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆï¼Œä»¥ä¾¿è°ƒè¯•
                import traceback
                traceback.print_exc()
                time.sleep(random.uniform(4, 8))
        
        error_msg = f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_name}"
        print(error_msg)
        return False
    
    def download_album(self, album_info):
        """ä¸‹è½½å•ä¸ªç›¸å†Œ"""
        sanitized_name, original_name, album_url = album_info
        
        # æ‰“å°ç›¸å†Œå¼€å§‹ä¿¡æ¯
        print(f"\nğŸŠ å¼€å§‹ä¸‹è½½ç›¸å†Œ: {original_name}")
        print(f"ğŸ“š ç›¸å†Œé“¾æ¥: {album_url}")
        logger.info(f"å¼€å§‹ä¸‹è½½ç›¸å†Œ: {original_name}")
        
        # å°†ç›¸å†Œæ·»åŠ åˆ°æ­£åœ¨ä¸‹è½½åˆ—è¡¨
        self.downloading_list.append(original_name)
        
        # åˆ›å»ºç›¸å†Œç›®å½•
        album_dir = os.path.join(self.save_path, sanitized_name)
        if not os.path.exists(album_dir):
            print(f"ğŸ“ åˆ›å»ºç›¸å†Œç›®å½•: {album_dir}")
            os.makedirs(album_dir)
        
        try:
            # éšæœºå»¶è¿Ÿ4-8ç§’
            delay = random.uniform(4, 8)
            print(f"â±ï¸  éšæœºå»¶è¿Ÿ {delay:.1f} ç§’...")
            time.sleep(delay)
            
            # è·å–ç›¸å†Œé¡µé¢å†…å®¹
            print(f"ğŸ”— è·å–ç›¸å†Œé¡µé¢å†…å®¹...")
            response = self.session.get(album_url, timeout=30)
            response.raise_for_status()
            
            # è§£æç›¸å†Œé¡µé¢ï¼Œè·å–æ‰€æœ‰å›¾ç‰‡é“¾æ¥
            print(f"ğŸ” è§£æç›¸å†Œé¡µé¢ï¼Œæå–å›¾ç‰‡é“¾æ¥...")
            soup = BeautifulSoup(response.text, 'html.parser')
            image_tags = soup.find_all('img')
            image_urls = []
            
            for img in image_tags:
                if 'src' in img.attrs:
                    img_url = img['src']
                    # è¿‡æ»¤æ‰ä¸éœ€è¦çš„å›¾ç‰‡ï¼ˆåªä¿ç•™jpg, jpeg, png, gifï¼‰
                    if img_url.endswith(('.jpg', '.jpeg', '.png', '.gif')):
                        image_urls.append(img_url)
            
            total_images = len(image_urls)
            print(f"ğŸ“¸ ç›¸å†ŒåŒ…å« {total_images} å¼ å›¾ç‰‡")
            logger.info(f"ç›¸å†Œ {original_name} åŒ…å« {total_images} å¼ å›¾ç‰‡")
            
            # å¹¶å‘ä¸‹è½½ç›¸å†Œä¸­çš„å›¾ç‰‡ - é™åˆ¶å›¾ç‰‡çº§å¹¶å‘ä¸º3-5ä¸ª
            success_count = 0
            skip_count = 0
            fail_count = 0
            
            # é™åˆ¶å›¾ç‰‡çº§å¹¶å‘æ•°ï¼Œé¿å…å¹¶å‘è¿‡é«˜
            img_max_workers = random.randint(3, 5)
            print(f"ğŸš€ å¼€å§‹ä¸‹è½½ç›¸å†Œä¸­çš„å›¾ç‰‡ï¼Œä½¿ç”¨ {img_max_workers} ä¸ªå›¾ç‰‡å¹¶å‘çº¿ç¨‹...")
            with concurrent.futures.ThreadPoolExecutor(max_workers=img_max_workers) as executor:
                futures = {}
                for i, img_url in enumerate(image_urls):
                    # ä½¿ç”¨åŸæ–‡ä»¶åä¿å­˜å›¾ç‰‡
                    img_name = os.path.basename(img_url.split('?')[0])
                    img_path = os.path.join(album_dir, img_name)
                    
                    # å¦‚æœå›¾ç‰‡å·²å­˜åœ¨ä¸”éªŒè¯é€šè¿‡ï¼Œåˆ™è·³è¿‡
                    if os.path.exists(img_path):
                        if self.validate_image(img_path):
                            skip_msg = f"âœ… å›¾ç‰‡ {img_name} å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½"
                            print(skip_msg)
                            logger.info(f"[{original_name}] å›¾ç‰‡ {img_name} å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½")
                            skip_count += 1
                            success_count += 1
                            continue
                        else:
                            print(f"ğŸ”„ å›¾ç‰‡ {img_name} å·²å­˜åœ¨ä½†æŸåï¼Œé‡æ–°ä¸‹è½½")
                            logger.info(f"[{original_name}] å›¾ç‰‡ {img_name} å·²å­˜åœ¨ä½†æŸåï¼Œé‡æ–°ä¸‹è½½")
                    
                    future = executor.submit(self.download_image, img_url, img_path)
                    futures[future] = (img_url, img_name)
                
                # ç­‰å¾…æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆ
                total_futures = len(futures)
                completed_futures = 0
                
                for future in concurrent.futures.as_completed(futures):
                    completed_futures += 1
                    img_url, img_name = futures[future]
                    try:
                        result = future.result()
                        if result:
                            success_count += 1
                            print(f"ğŸ“Š ç›¸å†Œè¿›åº¦: {completed_futures}/{total_futures} å¼ ï¼ŒæˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count}")
                        else:
                            fail_count += 1
                            print(f"ğŸ“Š ç›¸å†Œè¿›åº¦: {completed_futures}/{total_futures} å¼ ï¼ŒæˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count}")
                    except Exception as e:
                        fail_count += 1
                        print(f"ğŸ“Š ç›¸å†Œè¿›åº¦: {completed_futures}/{total_futures} å¼ ï¼ŒæˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count}")
                        logger.error(f"[{original_name}] å¤„ç†å›¾ç‰‡ {img_name} æ—¶å‡ºé”™: {e}")
            
            # ä¸‹è½½å®Œæˆæ€»ç»“
            summary_msg = f"ğŸ‰ ç›¸å†Œä¸‹è½½å®Œæˆ: {original_name}"
            print(f"\n{summary_msg}")
            print(f"ğŸ“Š ç›¸å†Œç»Ÿè®¡: æ€»å›¾ç‰‡æ•°: {total_images}, æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, è·³è¿‡: {skip_count}")
            print(f"ğŸ“ ä¿å­˜ç›®å½•: {album_dir}")
            
            logger.info(f"ç›¸å†Œ {original_name} ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ {success_count}/{total_images} å¼ å›¾ç‰‡")
            
            # ä»æ­£åœ¨ä¸‹è½½åˆ—è¡¨ç§»é™¤ï¼Œæ·»åŠ åˆ°å·²å®Œæˆåˆ—è¡¨
            self.downloading_list.remove(original_name)
            self.completed_list.append(original_name)
            
            return True
        except requests.exceptions.RequestException as e:
            error_msg = f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œå¤„ç†ç›¸å†Œ {original_name} æ—¶å‡ºé”™: {e}"
            print(f"\n{error_msg}")
            logger.error(error_msg)
            # ä»æ­£åœ¨ä¸‹è½½åˆ—è¡¨ç§»é™¤ï¼Œæ·»åŠ åˆ°å¤±è´¥åˆ—è¡¨
            if original_name in self.downloading_list:
                self.downloading_list.remove(original_name)
            self.failed_list.append(original_name)
            return False
        except Exception as e:
            error_msg = f"âŒ å¤„ç†ç›¸å†Œ {original_name} æ—¶å‡ºé”™: {e}"
            print(f"\n{error_msg}")
            logger.error(error_msg)
            # ä»æ­£åœ¨ä¸‹è½½åˆ—è¡¨ç§»é™¤ï¼Œæ·»åŠ åˆ°å¤±è´¥åˆ—è¡¨
            if original_name in self.downloading_list:
                self.downloading_list.remove(original_name)
            self.failed_list.append(original_name)
            return False
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        start_time = time.time()
        print("ğŸš€ å¼€å§‹è¿è¡Œçˆ¬è™«...")
        print(f"ğŸ“… å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è·å–æ‰€æœ‰ç›¸å†Œ
        print("\nğŸ¯ é˜¶æ®µ1: è·å–æ‰€æœ‰ç›¸å†Œ")
        albums = self.get_all_albums()
        total_albums = len(albums)
        print(f"ğŸ‰ å…±è·å–åˆ° {total_albums} ä¸ªç›¸å†Œ")
        
        # å°†æ‰€æœ‰ç›¸å†Œæ·»åŠ åˆ°å¾…ä¸‹è½½åˆ—è¡¨
        self.waiting_list = [album[1] for album in albums]
        print(f"ğŸ“‹ å¾…ä¸‹è½½åˆ—è¡¨å·²æ›´æ–°ï¼Œå…± {len(self.waiting_list)} ä¸ªç›¸å†Œ")
        
        # å¹¶å‘ä¸‹è½½ç›¸å†Œï¼ˆ3-5ä¸ªå¹¶å‘ï¼‰
        max_workers = random.randint(3, 5)
        print(f"\nğŸ¯ é˜¶æ®µ2: å¼€å§‹ä¸‹è½½ç›¸å†Œ")
        print(f"âš¡ ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹")
        print(f"ğŸ“ ä¸‹è½½ç­–ç•¥: æ¯ä¸ªç›¸å†Œéšæœºå»¶è¿Ÿ4-8ç§’ï¼Œæ¯ä¸ªå›¾ç‰‡éšæœºå»¶è¿Ÿ4-8ç§’")
        
        # ç®€å•ä¸‹è½½ï¼Œä¸ä½¿ç”¨å¤æ‚çš„è¿›åº¦ç›‘æ§
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            print(f"\nğŸ“Š å…¨å±€è¿›åº¦ç›‘æ§:")
            print(f"å¼€å§‹ä¸‹è½½...")
            
            # æ‰§è¡Œä¸‹è½½
            futures = {}
            for i, album in enumerate(albums):
                future = executor.submit(self.download_album, album)
                futures[future] = album[1]
            
            # å®æ—¶ç›‘æ§è¿›åº¦
            completed_albums = 0
            for future in concurrent.futures.as_completed(futures):
                completed_albums += 1
                album_name = futures[future]
                
                # è®¡ç®—å½“å‰è¿›åº¦
                progress = completed_albums / total_albums * 100
                elapsed_time = time.time() - start_time
                albums_per_minute = completed_albums / (elapsed_time / 60) if elapsed_time > 0 else 0
                
                print(f"ğŸ“Š å…¨å±€è¿›åº¦: {progress:.1f}% ({completed_albums}/{total_albums} ä¸ªç›¸å†Œ)ï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’ï¼Œé€Ÿåº¦: {albums_per_minute:.1f} ä¸ª/åˆ†é’Ÿ")
                print(f"ğŸ“‹ å½“å‰çŠ¶æ€: å¾…ä¸‹è½½: {len(self.waiting_list)}, æ­£åœ¨ä¸‹è½½: {len(self.downloading_list)}, å·²å®Œæˆ: {len(self.completed_list)}, å¤±è´¥: {len(self.failed_list)}")
        
        # å¤„ç†å¤±è´¥åˆ—è¡¨
        if self.failed_list:
            print(f"\nâš ï¸  ä¸‹è½½å®Œæˆï¼å‘ç°å¤±è´¥é¡¹")
            print(f"ğŸ“‹ å¤±è´¥åˆ—è¡¨: {self.failed_list}")
            print(f"ğŸ“Š åˆæ­¥ç»Ÿè®¡: æ€»ç›¸å†Œæ•°: {total_albums}, æˆåŠŸ: {len(self.completed_list)}, å¤±è´¥: {len(self.failed_list)}")
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦é‡è¯•å¤±è´¥çš„ç›¸å†Œ
            while True:
                user_input = input("\nğŸ”„ æ˜¯å¦é‡è¯•å¤±è´¥çš„ç›¸å†Œï¼Ÿ(y/n): ").strip().lower()
                if user_input in ['y', 'n']:
                    break
                print("è¯·è¾“å…¥ y æˆ– n")
            
            if user_input == 'y':
                print("\nğŸ”„ å¼€å§‹é‡è¯•å¤±è´¥çš„ç›¸å†Œ...")
                
                # å‡†å¤‡é‡è¯•çš„ç›¸å†Œåˆ—è¡¨
                retry_albums = []
                for album in albums:
                    if album[1] in self.failed_list:
                        retry_albums.append(album)
                
                print(f"ğŸ“‹ å‡†å¤‡é‡è¯• {len(retry_albums)} ä¸ªå¤±è´¥çš„ç›¸å†Œ")
                
                # é‡ç½®å¤±è´¥åˆ—è¡¨
                self.failed_list = []
                
                # é‡è¯•ä¸‹è½½
                with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = {}
                    for album in retry_albums:
                        future = executor.submit(self.download_album, album)
                        futures[future] = album[1]
                    
                    # å®æ—¶ç›‘æ§é‡è¯•è¿›åº¦
                    completed_retry = 0
                    total_retry = len(retry_albums)
                    for future in concurrent.futures.as_completed(futures):
                        completed_retry += 1
                        album_name = futures[future]
                        progress = completed_retry / total_retry * 100
                        print(f"ğŸ“Š é‡è¯•è¿›åº¦: {progress:.1f}% ({completed_retry}/{total_retry} ä¸ªç›¸å†Œ)")
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print(f"\nğŸ† æœ€ç»ˆä¸‹è½½ç»“æœï¼")
        print(f"ğŸ“… ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é’Ÿ)")
        print(f"ğŸ“Š å…¨å±€ç»Ÿè®¡:")
        print(f"   æ€»ç›¸å†Œæ•°: {total_albums}")
        print(f"   æˆåŠŸä¸‹è½½: {len(self.completed_list)}")
        print(f"   ä¸‹è½½å¤±è´¥: {len(self.failed_list)}")
        print(f"   æˆåŠŸç‡: {len(self.completed_list)/total_albums*100:.1f}%")
        
        # æ˜¾ç¤ºå„ä¸ªåˆ—è¡¨
        print(f"\nğŸ“‹ åˆ—è¡¨è¯¦æƒ…:")
        print(f"   å¾…ä¸‹è½½åˆ—è¡¨: {self.waiting_list}")
        print(f"   æ­£åœ¨ä¸‹è½½åˆ—è¡¨: {self.downloading_list}")
        print(f"   å·²å®Œæˆåˆ—è¡¨: {self.completed_list}")
        print(f"   å¤±è´¥åˆ—è¡¨: {self.failed_list}")
        
        print(f"\nğŸ‰ çˆ¬è™«è¿è¡Œå®Œæˆï¼")
    
    def verify_existing_files(self):
        """éªŒè¯å¹¶ä¿®å¤å·²å­˜åœ¨çš„æŸåæ–‡ä»¶"""
        logger.info("å¼€å§‹éªŒè¯å·²å­˜åœ¨çš„æ–‡ä»¶...")
        
        # éå†æ‰€æœ‰ç›¸å†Œç›®å½•
        for album_name in os.listdir(self.save_path):
            album_dir = os.path.join(self.save_path, album_name)
            if not os.path.isdir(album_dir):
                continue
            
            logger.info(f"éªŒè¯ç›¸å†Œ: {album_name}")
            
            # éå†ç›¸å†Œä¸­çš„æ‰€æœ‰å›¾ç‰‡
            for img_name in os.listdir(album_dir):
                img_path = os.path.join(album_dir, img_name)
                if not os.path.isfile(img_path):
                    continue
                
                # å¦‚æœå›¾ç‰‡æŸåï¼Œåˆ™åˆ é™¤
                if not self.validate_image(img_path):
                    logger.info(f"åˆ é™¤æŸåçš„å›¾ç‰‡: {img_path}")
                    os.remove(img_path)
        
        logger.info("æ–‡ä»¶éªŒè¯å®Œæˆï¼")

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="é­…å½±å›¾åº“çˆ¬è™«")
    parser.add_argument('--save-path', type=str, default="E:achongæœå½±å›¾åº“    xxtu.org", help="å›¾ç‰‡ä¿å­˜è·¯å¾„")
    parser.add_argument('--verify', action='store_true', help="éªŒè¯å¹¶ä¿®å¤å·²å­˜åœ¨çš„æŸåæ–‡ä»¶")
    args = parser.parse_args()
    
    # è¯¢é—®ç”¨æˆ·ä¿å­˜åœ°å€ï¼Œè‹¥ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤
    default_path = args.save_path
    print(f"é»˜è®¤ä¿å­˜è·¯å¾„: {default_path}")
    user_input = input("è¯·è¾“å…¥è‡ªå®šä¹‰ä¿å­˜è·¯å¾„ï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤ï¼‰: ").strip()
    
    if user_input:
        save_path = user_input
        print(f"ä½¿ç”¨è‡ªå®šä¹‰ä¿å­˜è·¯å¾„: {save_path}")
    else:
        save_path = default_path
        print(f"ä½¿ç”¨é»˜è®¤ä¿å­˜è·¯å¾„: {save_path}")
    
    # åˆå§‹åŒ–çˆ¬è™«
    crawler = GalleryCrawler(save_path, args.verify)
    
    # å¦‚æœå¯ç”¨äº†éªŒè¯æ¨¡å¼ï¼Œåˆ™å…ˆéªŒè¯å·²å­˜åœ¨çš„æ–‡ä»¶
    if args.verify:
        crawler.verify_existing_files()
    
    # å¼€å§‹çˆ¬å–
    crawler.run()

if __name__ == "__main__":
    main()